<!DOCTYPE html>
<html>
<head>
  <title>Autoencoders: Denoising</title>
  <link href="https://fonts.googleapis.com/css?family=Raleway:300|Source+Code+Pro" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="../css/normalise.css">
  <link rel="stylesheet" type="text/css" href="../css/global.css">
  <link rel="stylesheet" type="text/css" href="../css/content.css">
</head>
<body>
  <!-- Menu -->
  <span class="hamburger"></span>
  <nav class="hidden">
    <div class="brand">
      <a href="../"><img src="../img/logo.svg"> AUTOENCODERS</a>
    </div>
    <ul>
      <li><a href="#" content="neural-networks">Neural Networks</a></li>
      <li class="hidden" content="neural-networks">
        <ul>
          <li><a href="../neural-networks">Introduction</a></li>
          <li><a href="../neural-networks/neurons.html">Artificial Neurons</a></li>
          <li><a href="../neural-networks/learning.html">Learning</a></li>
          <li><a href="../neural-networks/regularisation.html">Regularisation</a></li>
          <li><a href="../neural-networks/optimisers.html">Optimisers</a></li>
        </ul>
      </li>
      <li><a href="#" content="autoencoders">Autoencoders</a></li>
      <li class="hidden" content="autoencoders">
        <ul>
          <li><a href="../autoencoders">Introduction</a></li>
          <li><a href="../autoencoders/denoising.html">Autoencoders for Denoising</a></li>
          <li><a href="../autoencoders/variational.html">Variational Autoencoders</a></li>
          <li><a href="../autoencoders/sparse.html">Sparse Autoencoders</a></li>
          <li><a href="../autoencoders/ip.html">Usage in Image Processing</a></li>
        </ul>
      </li>
      <li class="last"><a href="#" content="nlp">Autoencoders in NLP</a></li>
      <li class="hidden last" content="nlp">
        <ul>
          <li><a href="../nlp">Introduction</a></li>
          <li><a href="../nlp/word-phrase.html">Word and Phrase Representations</a></li>
          <li><a href="../nlp/bilingual.html">Bilingual Phrase Representations</a></li>
          <li><a href="../nlp/recursive.html">Recursive Autoencoders</a></li>
          <li><a href="../nlp/sentiment.html">Sentiment Analysis</a></li>
          <li><a href="../nlp/paraphrase.html">Paraphrase Detection</a></li>
        </ul>
      </li>
    </ul>
    <div class="close"></div>
  </nav>
  <div class="overlay hidden"></div>

  <div class="container">
    <!-- BEGIN: LyX Generated HTML -->
    <h2 class="titleHead">Denoising Autoencoders</h2>
    The principle behind denoising autoencoders is to be able to reconstruct data from an input of corrupted data. After giving the autoencoder the corrupted data, we force the hidden layer to learn only the more robust features, rather than just the identity. The output will then be a more refined version of the input data <span class="cite">[<a href="#Xdeeplearning">1</a>]</span>. <!--l. 32-->
    <p class="noindent">We can train a denoising autoencoder by stochastically corrupting data sets and inputting them into a neural network. The autoencoder can then be trained against the original data. One way to corrupt the data would be simply to randomly remove some parts of the data, so that the autoencoder is trying to predict the missing input. <!--l. 38--></p>
    <p class="noindent">An example of this is shown below, with the image an autoencoder is trained on being on the left, and a reconstruction of the middle image on the right. <!--l. 42--></p>
    <p class="noindent"></p>
    <div class="figure">
      <a id="x1-2r1"></a> <!--l. 44-->
      <p class="noindent"><img alt="PIC" src="../img/autoencoders/denoising-example.png"><br></p>
      <div class="caption">
        <span class="id">Figure&#x00A0;1:</span> <span class="content">Denoising autoencoder example on handwritten digits <span class="cite">[<a href="#Xopendeep">2</a>]</span>.</span>
      </div><!--tex4ht:label?: x1-2r1 -->
      <!--l. 48-->
      <p class="noindent"></p>
    </div>
    <!--l. 51-->
    <a id="pre-training"></a>
    <p class="noindent"><span class="paragraphHead"><a id="x1-20001"></a><span class="cmbx-10">Pretraining</span></span> Stacked denoising autoencoders are also useful for deep learning. A stacked denoising autoencoder is a denoising autoencoder with multiple hidden layers, and is trained layer by layer, by trying to minimize the error in the layer&#8217;s reconstruction compared to it&#8217;s input (the previous layer&#8217;s output). By using a stacked autoencoder in an unsupervised manner, we can learn starting weights prior to the main supervised training procedure with deep learning. A regularization effect is then created as a result of the pretraining procedure creating an initialization point, to which the parameters are restricted to a near optimal local minimum <span class="cite">[<a href="#XERHAN2010">3</a>]</span>. <!--l. 62--></p>
    <p class="noindent"></p>
    <div class="figure">
      <a id="x1-3r2"></a> <!--l. 63-->
      <p class="noindent"><img alt="PIC" src="../img/autoencoders/pretraining-deep-networks.png"><br></p>
      <div class="caption">
        <span class="id">Figure&#x00A0;2:</span> <span class="content">Pretraining example visualization <span class="cite">[<a href="#XERHAN2010">3</a>]</span>.</span>
      </div><!--tex4ht:label?: x1-3r2 -->
      <!--l. 68-->
      <p class="noindent"></p>
    </div>
    <!--l. 71-->
    <p class="noindent">The above image, is a 2D visualization generated with ISOMAP of the functions represented by 50 networks with and 50 networks without pretraining, for supervised training over MNIST (handwritten digits database) with 2 hidden layers. The colours from deep blue to cyan represent the progression in iterations. As the image shows, the pretraining models all start in a small region of space and decrease in variance, towards a basin of attraction. The training was also quicker by pretraining the functions.</p>
    <!-- END: LyX Generated HTML -->
    <div class="navigation">
      <a class="button" href="index.html">Previous</a>
      <a class="button dark next" href="variational.html">Next</a>
      <div class="clearfix"></div>
    </div>
  </div>
  <div class="well">
    <div class="container">
      <!-- BEGIN: LyX Generated HTML -->
      <h3 class="likesectionHead"><a id="x1-1000"></a>References</h3><!--l. 1-->
      <p class="noindent"></p>
      <div class="thebibliography">
        <p class="bibitem"><span class="biblabel">[1]<span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span><a id="Xdeeplearning"></a>DeepLearning. Denoising Autoencoders;. Available from: <a class="url" href="http://deeplearning.net/tutorial/dA.html"><span class="cmtt-10">http://deeplearning.net/tutorial/dA.html</span></a>.</p>
        <p class="bibitem"><span class="biblabel">[2]<span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span><a id="Xopendeep"></a>OpenDeep. Tutorial: Your First Model (DAE);. Available from: <a class="url" href="http://www.opendeep.org/v0.0.5/docs/tutorial-your-first-model"><span class="cmtt-10">http://www.opendeep.org/v0.0.5/docs/tutorial-_your-_first-_model</span></a>.</p>
        <p class="bibitem"><span class="biblabel">[3]<span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span><a id="XERHAN2010"></a>et&#x00A0;al E. Why does Unsupervised Pre-training Help Deep Learning?;. Available from: <a class="url" href="http://www.jmlr.org/papers/volume11/erhan10a/erhan10a.pdf"><span class="cmtt-10">http://www.jmlr.org/papers/volume11/erhan10a/erhan10a.pdf</span></a>.</p>
      </div>
      <!-- END: LyX Generated HTML -->
    </div>
  </div>
  <script type="text/javascript" src="../js/jquery.min.js"></script>
  <script type="text/javascript" src="../js/global.js"></script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
  </script>
  <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
</body>
</html>
