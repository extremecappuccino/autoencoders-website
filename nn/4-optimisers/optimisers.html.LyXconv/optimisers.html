<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>Optimisers</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.cse.ohio-state.edu/~gurari/TeX4ht/)"> 
<!-- html --> 
<meta name="src" content="optimisers.tex"> 
<meta name="date" content="2017-03-14 12:20:00"> 
<link rel="stylesheet" type="text/css" href="optimisers.css"> 
</head><body 
>
<div class="maketitle">
                                                                                         
                                                                                         
                                                                                         
                                                                                         

<h2 class="titleHead">Optimisers</h2>
<div class="author" ><span 
class="cmr-12">Laurence Squires</span></div>
<br />
<div class="date" ><span 
class="cmr-12">March 14, 2017</span></div>
</div>
<h3 class="sectionHead"><span class="titlemark">1   </span> <a 
 id="x1-10001"></a>Gradient Descent</h3>
<!--l. 33--><p class="noindent" >Gradient descent is the general purpose way to minimize a cost function <span 
class="cmmi-10">J</span>(<span 
class="cmmi-10">&#x03B8;</span>) with <span 
class="cmmi-10">&#x03B8;</span> being the parameters of the
model (such as weights and biases). The learning rate <span 
class="cmmi-10">&eta;</span> determines the speed at which it learns, and the step size
we take at each update interval, too slow a learning rate and convergence to the minimum takes too
long, too high the learning rate and the parameters will not reach the minimum as they will not get
fine-tuned.
<!--l. 42--><p class="noindent" >There are three main ways to do gradient descent, and choosing the correct one depends on the amount of data and
the trade-off the user makes between speed and accuracy.
<!--l. 47--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">1.1   </span> <a 
 id="x1-20001.1"></a>Batch gradient descent</h4>
<!--l. 49--><p class="noindent" >This is the most basic type of gradient descent and works well for small data sets. It computes the gradient of the
cost function with respect to the parameters of the model for the entire model. This version of gradient descent is
very slow and very expensive as the entire data set needs to be processed for one update. Furthermore, using this
version on modern machine learning frameworks doesn&#8217;t support the adding of new examples (on-the-fly learning)
as the model is training, the reason for this is because the input is the entire data set the model is
designed to take inputs of that size, and any change to the size of the inputs requires reloading of the
model.
<!--l. 61--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">1.2   </span> <a 
 id="x1-30001.2"></a>Stochastic gradient descent</h4>
<!--l. 63--><p class="noindent" >Stochastic gradient descent (SGD) is gradient descent performed for each input, so each update interval occurs after
one input has been processed through the network. This is a faster way of training the model than batch gradient
descent as batch will perform redundant computations for each update cycle as it computes the whole data set and
so the update is not granted to affect the performance of a single input. In addition, SGD allows for on the fly
                                                                                         
                                                                                         
learning as the input size isn&#8217;t changed by adding more examples to the data set. The downside is that while
training the model the cost function will fluctuate wildly as each input is different from each other. This is shown in
the graph below.
<!--l. 75--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-3001r1"></a>
                                                                                         
                                                                                         
<!--l. 76--><p class="noindent" > <img 
src="0_home_jordanspooner_Documents_163_Computing_To___encoders-website_nn_4-optimisers_res_Stogra.png" alt="PIC"  
>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;1: </span><span  
class="content">Wild fluctuation in the SGD cost function while training <span class="cite">[<a 
href="#XsgdTraining">1</a>]</span></span></div><!--tex4ht:label?: x1-3001r1 -->
                                                                                         
                                                                                         
<!--l. 81--><p class="noindent" ></div><hr class="endfigure">
<h4 class="subsectionHead"><span class="titlemark">1.3   </span> <a 
 id="x1-40001.3"></a>Mini-batch gradient descent</h4>
<!--l. 87--><p class="noindent" >Mini-batch gradient descent is a mixture of the two previous methods. Instead of training the network on the entire
data set, the data set is partitioned into batches of fixed size and then fed into the model for training. This enables
it the converge fast like SGD but can also be computed faster, most modern day machine learning libraries take
advantage of the GPU and its ability to perform large matrix calculations quickly, by fixing the input size bigger
than 1 (such as in SGD) this enables the entire input to be generalized and stored in memory as a tensor (higher
dimensional matrix) and then computed through the model very quickly by the GPU. This method then
utilizes the best of the previous methods and is normally the chosen method for practical machine
learning.
<!--l. 101--><p class="noindent" >
<h3 class="sectionHead"><span class="titlemark">2   </span> <a 
 id="x1-50002"></a>Optimisers</h3>
<!--l. 103--><p class="noindent" >For all the previous examples we have used the simplest form of the gradient descent algorithm. Simply calculating
the gradient of the cost function, multiplying it by a constant learning rate and then subtracting it from the current
the parameters so our parameters take a tiny step in the direction we hope minimises the cost function. This is
shown in the update algorithm below.
<!--l. 110--><p class="noindent" >
<div class="center" 
>
<!--l. 110--><p class="noindent" >
<!--l. 111--><p class="noindent" ><span 
class="cmmi-10">&#x03B8;</span> = <span 
class="cmmi-10">&#x03B8;</span> <span 
class="cmsy-10">&minus;</span> <span 
class="cmmi-10">&eta;</span><span 
class="cmsy-10">&nabla;</span>J(<span 
class="cmmi-10">&#x03B8;</span>)
</div>
<!--l. 115--><p class="noindent" >
<h4 class="subsectionHead"><span class="titlemark">2.1   </span> <a 
 id="x1-60002.1"></a>Momentum</h4>
<!--l. 117--><p class="noindent" >The normal gradient descent algorithm has difficulty dealing with ravines, or places with much sharper surface
curves in one dimension. This causes our parameters to constantly &#8220;roll&#8221; from one side of the ravine to
the other as the gradient in these places is much larger than the gradient leading us to the optimal
solution.
<!--l. 123--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-6001r2"></a>
                                                                                         
                                                                                         
<!--l. 124--><p class="noindent" > <img 
src="1_home_jordanspooner_Documents_163_Computing_To___ebsite_nn_4-optimisers_res_without_momentum.png" alt="PIC"  
>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;2: </span><span  
class="content">The update steps without momentum</span></div><!--tex4ht:label?: x1-6001r2 -->
                                                                                         
                                                                                         
<!--l. 129--><p class="noindent" ></div><hr class="endfigure">
<!--l. 132--><p class="noindent" >Momentum is a method that helps deal with this problem by simply adding a momentum to the update step. It
achieves this by adding a fraction of the past update vector to the current vector.
<!--l. 136--><p class="noindent" >
<div class="center" 
>
<!--l. 136--><p class="noindent" >
<!--l. 137--><p class="noindent" ><span 
class="cmmi-10">v</span><sub><span 
class="cmmi-7">t</span></sub> = 0<span 
class="cmmi-10">.</span>9 <span 
class="cmsy-10">&lowast; </span><span 
class="cmmi-10">v</span><sub><span 
class="cmmi-7">t</span><span 
class="cmsy-7">&minus;</span><span 
class="cmr-7">1</span></sub> + <span 
class="cmmi-10">&eta;</span><span 
class="cmsy-10">&nabla;</span><span 
class="cmmi-10">J</span>(<span 
class="cmmi-10">&#x03B8;</span>)
</div>
<!--l. 140--><p class="noindent" >
<div class="center" 
>
<!--l. 140--><p class="noindent" >
<!--l. 141--><p class="noindent" ><span 
class="cmmi-10">&#x03B8; </span>= <span 
class="cmmi-10">&#x03B8; </span><span 
class="cmsy-10">&minus; </span><span 
class="cmmi-10">v</span><sub><span 
class="cmmi-7">t</span></sub>
</div>
<!--l. 144--><p class="noindent" >Therefore, our updates accumulate momentum in the correct direction and reach the optimal solution much faster,
as shown in this diagram. This is similar to how a ball rolls down a hill or ravine, accumulating velocity in the
direction towards the lowest point.
<!--l. 149--><p class="noindent" ><hr class="figure"><div class="figure" 
>
                                                                                         
                                                                                         
<a 
 id="x1-6002r3"></a>
                                                                                         
                                                                                         
<!--l. 150--><p class="noindent" > <img 
src="2_home_jordanspooner_Documents_163_Computing_To___s-website_nn_4-optimisers_res_with_momentum.png" alt="PIC"  
>
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;3: </span><span  
class="content">The update step with momentum</span></div><!--tex4ht:label?: x1-6002r3 -->
                                                                                         
                                                                                         
<!--l. 155--><p class="noindent" ></div><hr class="endfigure">
<h3 class="likesectionHead"><a 
 id="x1-70002.1"></a>References</h3>
<!--l. 1--><p class="noindent" >
   <div class="thebibliography">
   <p class="bibitem" ><span class="biblabel">
 [1]<span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span><a 
 id="XsgdTraining"></a>Wikipedia.     Fluctuation     in     Cost     Function     for     SGD;.              Available     from:
   <a 
href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent" class="url" ><span 
class="cmtt-10">https://en.wikipedia.org/wiki/Stochastic_gradient_descent</span></a>.
</p>
   </div>
 
</body></html> 

                                                                                         


