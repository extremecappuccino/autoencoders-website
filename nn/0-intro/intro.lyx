#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage[hidelinks]{hyperref}
\usepackage{tikz}
\end_preamble
\use_default_options true
\begin_modules
InStar
\end_modules
\maintain_unincluded_children false
\begin_forced_local_layout
Format 60
Style "In Preamble"
	Category "FrontMatter"
	Margin Static
	LatexType Paragraph
	InTitle 0
	InPreamble 1
	TocLevel -1000
	NeedProtect 0
	KeepEmpty 0
	NextNoIndent 0
	CommandDepth 0
	LatexName "dummy"
	ItemCommand item
	LabelType No_Label
	EndLabelType No_Label
	ParagraphGroup "0"
	ParIndent MM
	ParSkip 0.4
	ItemSep 0
	TopSep 0
	BottomSep 0
	LabelBottomSep 0
	ParSep 0
	NewLine 1
	Align Block
	AlignPossible Block, Center, Layout, Left, Right
	FreeSpacing 0
	PassThru 0
	ParbreakIsNewline 0
	RefPrefix OFF
	HTMLLabelFirst 0
	HTMLStyle
div.standard {
margin-bottom: 2ex;
}
	EndHTMLStyle
	HTMLForceCSS 0
	HTMLTitle 0
	Spellcheck 1
	ForceLocal 1
End
Style "In Title"
	Category "FrontMatter"
	Margin Static
	LatexType Paragraph
	InTitle 1
	InPreamble 0
	TocLevel -1000
	NeedProtect 0
	KeepEmpty 0
	NextNoIndent 0
	CommandDepth 0
	LatexName "dummy"
	ItemCommand item
	LabelType No_Label
	EndLabelType No_Label
	ParagraphGroup "0"
	ParIndent MM
	ParSkip 0.4
	ItemSep 0
	TopSep 0
	BottomSep 0
	LabelBottomSep 0
	ParSep 0
	NewLine 1
	Align Block
	AlignPossible Block, Center, Layout, Left, Right
	FreeSpacing 0
	PassThru 0
	ParbreakIsNewline 0
	RefPrefix OFF
	HTMLLabelFirst 0
	HTMLStyle
div.standard {
margin-bottom: 2ex;
}
	EndHTMLStyle
	HTMLForceCSS 0
	HTMLTitle 0
	Spellcheck 1
	ForceLocal 1
End
\end_forced_local_layout
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Introduction to Neural Networks
\end_layout

\begin_layout Author
Qiang Feng
\end_layout

\begin_layout Section
Representation in Computing
\end_layout

\begin_layout Standard
A neural network is a model of computation that is roughly based on the
 structure of the biological brain 
\begin_inset CommandInset citation
LatexCommand cite
key "LeslieSmith2008"

\end_inset

.
 The brain consists of billions of neurons, which may have connections in
 the form of synapses.
 In computer science, this is modelled as a weighted graph, consisting of
 nodes (which resemble the neurons) and directed arcs connecting one node
 to another (this resembles the synapses) 
\begin_inset CommandInset citation
LatexCommand cite
key "KevinGurneyIntro"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Note Note
status open

\begin_layout Plain Layout
Neural Network Model
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Example of a Neural Network
\begin_inset CommandInset label
LatexCommand label
name "fig:Example-NN"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Example-NN"

\end_inset

 is a simple illustration of a neural network.
 Groups of neurons with similar functionality are clustered together into
 layers.
 These layers are then connected to different layers through the arcs in
 between their individual neurons.
 At the most basic, there is the input layer and the output layer.
\end_layout

\begin_layout Itemize
The input layer is where the information will be inserted into the neural
 network - the individual nodes of the input layer may be used for accepting
 specific features of the information (for example, if the information consists
 of Cartesian coordinates, there may be a node which accepts the 
\begin_inset Formula $x$
\end_inset

 coordinate, and a different node for accepting the 
\begin_inset Formula $y$
\end_inset

 coordinate).
\end_layout

\begin_layout Itemize
The output layer receives signals (information) from neurons in the previous
 layer, and then combines the possibly many signals to produce 1 output
 and then send this to where it is needed.
 There may be many different nodes in this layer which yield different attribute
s of the output information (for example, there may be a node to output
 the 
\begin_inset Formula $x$
\end_inset

 coordinate, and a different node to output the 
\begin_inset Formula $y$
\end_inset

 coordinate).
\end_layout

\begin_layout Standard
Between the input and output layers, there may exist a number of hidden
 layers 
\begin_inset CommandInset citation
LatexCommand cite
key "BasicPaperNN"

\end_inset

, which are used to perform more complicated data manipulation.
 For example, in a hidden layer, there may be a node which is used to detect
 a wheel in an image.
\end_layout

\begin_layout Section
Types of Neural Networks
\end_layout

\begin_layout Standard
Most neural networks follow the same general structure as the one described
 above.
 The difference between them comes from the ways they learn.
 The most basic type of neural network is a feed-forward network.
\end_layout

\begin_layout Subsection
Feed-Forward Neural Network
\end_layout

\begin_layout Standard
In this type of neural network, there are no cycles (i.e.
 there are no connections between neurons in the same layer) 
\begin_inset CommandInset citation
LatexCommand cite
key "MULFeedForward"

\end_inset

, so information flows only flows forward - from the input nodes, through
 any nodes in hidden layers, and finally to the output nodes.
\end_layout

\begin_layout Standard
Feed-forward neural networks are generally used for classifying data that
 is not dependent on time.
 An example usage is shown below - in this case, it is used to classify
 Cartesian coordinates.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename res/tf-ffnn.png
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:TensorFlowFFNN"

\end_inset

 Example of a Feed-Forward NN in TensorFlow Playground 
\begin_inset CommandInset citation
LatexCommand cite
key "TensorFlow"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Recurrent Neural Network
\end_layout

\begin_layout Standard
In some situations, the data being input into the neural network is time-depende
nt (i.e.
 the inputs are entered in a certain order which needs to be preserved in
 order to obtain the correct output).
 This is where standard feed-forward networks cannot help, as the algorithms
 used in calculating the output does not take time into account.
\end_layout

\begin_layout Standard
In a recurrent neural network, information may flow both ways - i.e.
 from layer 
\begin_inset Formula $i$
\end_inset

 to layer 
\begin_inset Formula $(i+x)$
\end_inset

, and also from layer 
\begin_inset Formula $(i+x)$
\end_inset

 to layer 
\begin_inset Formula $i$
\end_inset

.
\end_layout

\begin_layout Section
Uses of Neural Networks
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintAll"
bibfiles "intro"
options "vancouver"

\end_inset


\end_layout

\end_body
\end_document
